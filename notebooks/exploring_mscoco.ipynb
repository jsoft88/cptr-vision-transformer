{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_session = SparkSession.builder.master('local[*]').config('spark.driver.memory', '10G').config('spark.executor.memory', '8G').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trainval_2014 = spark_session.read.json('file:///workspace/d/ds_ai_stuff/datasets/mscoco/annotations_trainval2014/annotations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration for annotations_trainval2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- annotations: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- area: double (nullable = true)\n",
      " |    |    |-- bbox: array (nullable = true)\n",
      " |    |    |    |-- element: double (containsNull = true)\n",
      " |    |    |-- caption: string (nullable = true)\n",
      " |    |    |-- category_id: long (nullable = true)\n",
      " |    |    |-- id: long (nullable = true)\n",
      " |    |    |-- image_id: long (nullable = true)\n",
      " |    |    |-- iscrowd: long (nullable = true)\n",
      " |    |    |-- keypoints: array (nullable = true)\n",
      " |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |-- num_keypoints: long (nullable = true)\n",
      " |    |    |-- segmentation: string (nullable = true)\n",
      " |-- categories: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- id: long (nullable = true)\n",
      " |    |    |-- keypoints: array (nullable = true)\n",
      " |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- skeleton: array (nullable = true)\n",
      " |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |-- supercategory: string (nullable = true)\n",
      " |-- images: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- coco_url: string (nullable = true)\n",
      " |    |    |-- date_captured: string (nullable = true)\n",
      " |    |    |-- file_name: string (nullable = true)\n",
      " |    |    |-- flickr_url: string (nullable = true)\n",
      " |    |    |-- height: long (nullable = true)\n",
      " |    |    |-- id: long (nullable = true)\n",
      " |    |    |-- license: long (nullable = true)\n",
      " |    |    |-- width: long (nullable = true)\n",
      " |-- info: struct (nullable = true)\n",
      " |    |-- contributor: string (nullable = true)\n",
      " |    |-- date_created: string (nullable = true)\n",
      " |    |-- description: string (nullable = true)\n",
      " |    |-- url: string (nullable = true)\n",
      " |    |-- version: string (nullable = true)\n",
      " |    |-- year: long (nullable = true)\n",
      " |-- licenses: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- id: long (nullable = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- url: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_trainval_2014.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_df = df_trainval_2014.withColumn('id_caption', F.arrays_zip(F.col('annotations.id'), F.col('annotations.caption'), F.col('annotations.image_id')))\\\n",
    "    .select(F.explode(F.col('id_caption')).alias('id_caption'))\\\n",
    "    .select(\n",
    "        F.col('id_caption.id').alias('id'),\n",
    "        F.col('id_caption.caption').alias('caption'),\n",
    "        F.col('id_caption.image_id').alias('image_id')\n",
    "    ).alias('captions_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------------------------------------------------------------------+--------+\n",
      "|id |caption                                                                      |image_id|\n",
      "+---+-----------------------------------------------------------------------------+--------+\n",
      "|48 |A very clean and well decorated empty bathroom                               |318556  |\n",
      "|67 |A panoramic view of a kitchen and all of its appliances.                     |116100  |\n",
      "|126|A blue and white bathroom with butterfly themed wall tiles.                  |318556  |\n",
      "|148|A panoramic photo of a kitchen and dining room                               |116100  |\n",
      "|173|A graffiti-ed stop sign across the street from a red car                     |379340  |\n",
      "|188|A vandalized stop sign and a red beetle on the road                          |379340  |\n",
      "|219|A bathroom with a border of butterflies and blue paint on the walls above it.|318556  |\n",
      "|255|An angled view of a beautifully decorated bathroom.                          |318556  |\n",
      "|272|The two people are walking down the beach.                                   |134754  |\n",
      "|288|A sink and a toilet inside a small bathroom.                                 |538480  |\n",
      "|314|An empty kitchen with white and black appliances.                            |476220  |\n",
      "|328|A white square kitchen with tile floor that needs repairs                    |299675  |\n",
      "|352|The vanity contains two sinks with a towel for each.                         |32275   |\n",
      "|411|Several metal balls sit in the sand near a group of people.                  |302443  |\n",
      "|425|Two people carrying surf boards on a beach.                                  |134754  |\n",
      "|519|A kitchen with brown cabinets, tile backsplash, and grey counters.           |25470   |\n",
      "|572|A surfer, a woman, and a child walk on the beach.                            |513461  |\n",
      "|653|A few people sit on a dim transportation system.                             |18691   |\n",
      "|668|A person, protected from the rain by their umbrella, walks down the road.    |285579  |\n",
      "|674|The bathroom with a toilet has an interesting sink.                          |266366  |\n",
      "+---+-----------------------------------------------------------------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "captions_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_df = df_trainval_2014.withColumn('images_id_path', F.arrays_zip(F.col('images.id'), F.col('images.file_name'), F.col('images.height'), F.col('images.width')))\\\n",
    "    .select(F.explode(F.col('images_id_path')).alias('id_path_height_width'))\\\n",
    "    .select(\n",
    "        F.col('id_path_height_width.id').alias('image_id'),\n",
    "        F.col('id_path_height_width.file_name').alias('path'),\n",
    "        F.col('id_path_height_width.height').alias('height'),\n",
    "        F.col('id_path_height_width.width').alias('width')\n",
    "    ).alias('images_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------------------+------+-----+\n",
      "|image_id|path                           |height|width|\n",
      "+--------+-------------------------------+------+-----+\n",
      "|57870   |COCO_train2014_000000057870.jpg|480   |640  |\n",
      "|384029  |COCO_train2014_000000384029.jpg|429   |640  |\n",
      "|222016  |COCO_train2014_000000222016.jpg|640   |480  |\n",
      "|520950  |COCO_train2014_000000520950.jpg|427   |640  |\n",
      "|69675   |COCO_train2014_000000069675.jpg|480   |640  |\n",
      "|547471  |COCO_train2014_000000547471.jpg|640   |383  |\n",
      "|122688  |COCO_train2014_000000122688.jpg|640   |480  |\n",
      "|392136  |COCO_train2014_000000392136.jpg|347   |500  |\n",
      "|398494  |COCO_train2014_000000398494.jpg|640   |427  |\n",
      "|90570   |COCO_train2014_000000090570.jpg|429   |640  |\n",
      "|504616  |COCO_train2014_000000504616.jpg|640   |480  |\n",
      "|161919  |COCO_train2014_000000161919.jpg|612   |612  |\n",
      "|457732  |COCO_train2014_000000457732.jpg|640   |427  |\n",
      "|44404   |COCO_train2014_000000044404.jpg|480   |640  |\n",
      "|4428    |COCO_train2014_000000004428.jpg|640   |429  |\n",
      "|170558  |COCO_train2014_000000170558.jpg|640   |481  |\n",
      "|405613  |COCO_train2014_000000405613.jpg|383   |640  |\n",
      "|283524  |COCO_train2014_000000283524.jpg|480   |640  |\n",
      "|37015   |COCO_train2014_000000037015.jpg|480   |640  |\n",
      "|71631   |COCO_train2014_000000071631.jpg|425   |640  |\n",
      "+--------+-------------------------------+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "images_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = captions_df\\\n",
    "    .join(images_df, how='inner', on=F.col('captions_df.image_id') == F.col('images_df.image_id'))\\\n",
    "    .select(\n",
    "        F.col('captions_df.id').alias('id'),\n",
    "        F.col('captions_df.image_id').alias('image_id'),\n",
    "        F.col('captions_df.caption').alias('caption'),\n",
    "        F.col('images_df.path').alias('filename'),\n",
    "        F.col('images_df.height').alias('height'),\n",
    "        F.col('images_df.width').alias('width')\n",
    "    ).dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------------------+--------------------+------+-----+\n",
      "|     id|image_id|             caption|            filename|height|width|\n",
      "+-------+--------+--------------------+--------------------+------+-----+\n",
      "| 567271|      77|A young man ridin...|COCO_train2014_00...|   375|  500|\n",
      "| 569752|      77|a group of teenag...|COCO_train2014_00...|   375|  500|\n",
      "| 573184|      77|A time lapse imag...|COCO_train2014_00...|   375|  500|\n",
      "| 579604|      77|Group of boys per...|COCO_train2014_00...|   375|  500|\n",
      "| 582316|      77|some male skatebo...|COCO_train2014_00...|   375|  500|\n",
      "| 471474|      77|                null|COCO_train2014_00...|   375|  500|\n",
      "| 502475|      77|                null|COCO_train2014_00...|   375|  500|\n",
      "| 642036|      77|                null|COCO_train2014_00...|   375|  500|\n",
      "|1473417|      77|                null|COCO_train2014_00...|   375|  500|\n",
      "|1727807|      77|                null|COCO_train2014_00...|   375|  500|\n",
      "|1734810|      77|                null|COCO_train2014_00...|   375|  500|\n",
      "|1861309|      77|                null|COCO_train2014_00...|   375|  500|\n",
      "|2001992|      77|                null|COCO_train2014_00...|   375|  500|\n",
      "| 775939|     113|a man and woman c...|COCO_train2014_00...|   640|  416|\n",
      "| 780412|     113|A man and woman s...|COCO_train2014_00...|   640|  416|\n",
      "| 780745|     113|A women who is cu...|COCO_train2014_00...|   640|  416|\n",
      "| 781192|     113|two people standi...|COCO_train2014_00...|   640|  416|\n",
      "| 785659|     113|A woman cutting i...|COCO_train2014_00...|   640|  416|\n",
      "| 382563|     113|                null|COCO_train2014_00...|   640|  416|\n",
      "| 384638|     113|                null|COCO_train2014_00...|   640|  416|\n",
      "+-------+--------+--------------------+--------------------+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of entries per image id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+\n",
      "|image_id|count(id)|\n",
      "+--------+---------+\n",
      "|      77|       13|\n",
      "|     113|       23|\n",
      "|     196|       47|\n",
      "|     241|       19|\n",
      "|     415|        7|\n",
      "|     474|        7|\n",
      "|     486|       13|\n",
      "|     502|        6|\n",
      "|     564|       22|\n",
      "|     656|        8|\n",
      "|     724|        9|\n",
      "|     730|       11|\n",
      "|     831|       10|\n",
      "|     965|       10|\n",
      "|    1059|        6|\n",
      "|    1145|       46|\n",
      "|    1224|        7|\n",
      "|    1353|       12|\n",
      "|    1360|       12|\n",
      "|    1374|        7|\n",
      "+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joined_df.groupby(F.col('image_id')).agg({'id': 'count'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total number of entries without duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1513549"
      ]
     },
     "execution_count": 621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's filter all rows with empty or null caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_null_captions_df = joined_df.filter((~F.isnull(F.col('caption'))) & (F.length(F.col('caption')) > F.lit(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- image_id: long (nullable = true)\n",
      " |-- caption: string (nullable = true)\n",
      " |-- filename: string (nullable = true)\n",
      " |-- height: long (nullable = true)\n",
      " |-- width: long (nullable = true)\n",
      "\n",
      "root\n",
      " |-- image: struct (nullable = true)\n",
      " |    |-- origin: string (nullable = true)\n",
      " |    |-- height: integer (nullable = true)\n",
      " |    |-- width: integer (nullable = true)\n",
      " |    |-- nChannels: integer (nullable = true)\n",
      " |    |-- mode: integer (nullable = true)\n",
      " |    |-- data: binary (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "no_null_captions_df.printSchema()\n",
    "img_df = spark_session.read.format('image').load('file:///workspace/d/ds_ai_stuff/datasets/mscoco/train2014/train2014/')\n",
    "img_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total number of entries after filtering null captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "616767"
      ]
     },
     "execution_count": 624,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_null_captions_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_null_captions_df.filter(F.col('filename') == F.lit('COCO_train2014_000000005882.jpg')).coalesce(1).write.parquet('file:///workspace/d/cptr-vistion-transformer/tests/resources/metadata/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Captions stats\n",
    "\n",
    "* *TOTAL ROWS*: _1.513.549_\n",
    "* *TOTAL ROWS EXCLUDING NULL CAPTIONS*: _616.767_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see the length of captions and order by the descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_null_captions_df.withColumn('caption_len', F.length(F.col('caption'))).orderBy(F.col('caption_len'), ascending=False).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
